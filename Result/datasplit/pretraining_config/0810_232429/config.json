{
    "name": "pretraining_config",
    "n_gpu": 1,
    "dataset": {
        "type": "MLPDataset",
        "args": {
            "seed": 0,
            "seq_dir": "/home/keyang/snp2vec/sample_30000.txt",
            "vocab_dir": "/data/keyang/tokenizers",
            "prefix": "chr_diploid",
            "max_len": 4096,
            "test_split": 0.001
        }
    },
    "model": {
        "bert": "bert",
        "args": {
            "hidden_size": 768,
            "num_hidden_layers": 6,
            "num_attention_heads": 12,
            "intermediate_size": 3072,
            "hidden_act": "gelu",
            "hidden_dropout_prob": 0.1,
            "attention_probs_dropout_prob": 0.1,
            "max_position_embeddings": 512,
            "type_vocab_size": 2,
            "initializer_range": 0.02,
            "position_embedding_type": "absolute"
        }
    },
    "optimizer": {
        "type": "AdamW",
        "args": {
            "lr": 5e-05,
            "weight_decay": 0
        }
    },
    "metrics": [
        "rmse",
        "mae"
    ],
    "lr_scheduler": {
        "type": "StepLR",
        "args": {
            "step_size": 10,
            "gamma": 0.1
        }
    },
    "trainer": {
        "epochs": 25,
        "batch_size": 240,
        "save_dir": "../Result/",
        "lr": 0.0001,
        "warmup": 0.1,
        "eval_accumulation_steps": 1,
        "logging_steps": 500
    },
    "local_rank": null
}